{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "An Intro to the Earth Engine Python API",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kdsGkYJXXKc"
      },
      "source": [
        "#@title Copyright 2020 The Earth Engine Community Authors { display-mode: \"form\" }\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l18M9_r5XmAQ"
      },
      "source": [
        "# An Intro to the Earth Engine Python API\n",
        "\n",
        "Author: guiattard\n",
        "\n",
        "Within the last decade, a large amount of geospatial data, such as satellite data (e.g. land surface temperature, vegetation) or the output of large scale, even global models (e.g. wind speed, groundwater recharge), have become freely available from multiple national agencies and universities (e.g. NASA, USGS, NOAA, and ESA). These geospatial data are used every day by scientists and engineers of all fields, to predict weather, prevent disasters, secure water supply, or study the consequences of climate change. When using these geospatial data, a few questions arise:\n",
        "\n",
        "- What data are available and where can it be found?\n",
        "- How can we access these data?\n",
        "- How can we manipulate these petabytes of data?\n",
        "\n",
        "In this tutorial, an introduction to the [Google Earth Engine Python API](https://developers.google.com/earth-engine/guides/python_install) is presented. After some setup and some exploration of the Earth Engine Data Catalog, we’ll see how to handle geospatial datasets with [pandas](https://pandas.pydata.org/) and make some plots with matplotlib.\n",
        "\n",
        "First, we’ll see how to get the timeseries of a variable for a region of interest. An application of this procedure will be done to extract land surface temperature in an urban and a rural area near the city of Lyon, France to illustrate the heat island effect. Secondly, we will detail procedures for static mapping and exporting results as a GeoTIFF.\n",
        "\n",
        "Finally, the folium library will be introduced to make interactive maps. In this last part, we’ll see how to include some GEE datasets as tile layers of a folium map."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYiYem8wLSTX"
      },
      "source": [
        "## Exploration of the Earth Engine Data Catalog\n",
        "\n",
        "Have you ever thought that getting a meteorological dataset could be as easy as finding the nearest pizzeria? To convince you, visit the [Earth Engine Data Catalog](https://developers.google.com/earth-engine/datasets/catalog) and explore datasets using the search bar or browsing by tag.\n",
        "\n",
        "Let's say that we need to know the elevation of a region, some soil properties (e.g. clay, sand, silt content) and some meteorological observations (e.g. temperature, precipitation, evapotranspiration). Well, inside the Earth Engine Catalog we find:\n",
        "\n",
        "- [SRTM global elevation](https://developers.google.com/earth-engine/datasets/catalog/USGS_SRTMGL1_003) with a resolution of 30 m,\n",
        "- [OpenLandMap datasets](https://developers.google.com/earth-engine/datasets/catalog/OpenLandMap_SOL_SOL_CLAY-WFRACTION_USDA-3A1A1A_M_v02) with soil properties at a resolution of 250 m (e.g. clay, sand, and silt content), and\n",
        "- [GRIDMET](https://developers.google.com/earth-engine/datasets/catalog/IDAHO_EPSCOR_GRIDMET) temperature, precipitation, and evapotranspiration, for example.\n",
        "\n",
        "Of course the resolution, frequency, spatial and temporal extent, as well as data source (e.g. satellite image, interpolated station data, or model output) vary from one dataset to another. Therefore, read the description carefully and make sure you know what kind of dataset you are selecting!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7i55vr_aKCB"
      },
      "source": [
        "## Run me first\n",
        "\n",
        "First of all, run the following cell to initialize the API. The output will contain instructions on how to grant this notebook access to Earth Engine using your account."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeFsiSp2aDL6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e3d783b-7d41-4f9b-9084-aafa0f0f0e12"
      },
      "source": [
        "import ee\n",
        "from google.colab import auth\n",
        "# Trigger the authentication flow.\n",
        "ee.Authenticate()\n",
        "auth.authenticate_user(project_id=\"arizona-whirl\")\n",
        "# Initialize the library.\n",
        "ee.Initialize(project='arizona-whirl')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_auth_httplib2:httplib2 transport does not support per-request timeout. Set the timeout when constructing the httplib2.Http instance.\n",
            "WARNING:google_auth_httplib2:httplib2 transport does not support per-request timeout. Set the timeout when constructing the httplib2.Http instance.\n",
            "WARNING:google_auth_httplib2:httplib2 transport does not support per-request timeout. Set the timeout when constructing the httplib2.Http instance.\n",
            "WARNING:google_auth_httplib2:httplib2 transport does not support per-request timeout. Set the timeout when constructing the httplib2.Http instance.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ee.Number(1).add(1).getInfo())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wq6PWKxuhIBN",
        "outputId": "18f04105-f8b0-484e-d440-8e29d113090b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6WDkfesPYeV"
      },
      "source": [
        "# Import the nighttimelight collection\n",
        "viirs = ee.ImageCollection(\"NASA/VIIRS/002/VNP46A2\").select(\"Gap_Filled_DNB_BRDF_Corrected_NTL\")\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhoBd-aEPrD7"
      },
      "source": [
        "import pandas as pd\n",
        "cities_fc = ee.FeatureCollection(\"projects/arizona-whirl/assets/fl_cities\")\n",
        "cities = {\n",
        "    'Miami': cities_fc.filter(ee.Filter.eq('NAME', 'Miami')).geometry(),\n",
        "    'Tampa': cities_fc.filter(ee.Filter.eq('NAME', 'Tampa')).geometry(),\n",
        "    'Orlando': cities_fc.filter(ee.Filter.eq('NAME', 'Orlando')).geometry(),\n",
        "    'Jacksonville': cities_fc.filter(ee.Filter.eq('NAME', 'Jacksonville')).geometry(),\n",
        "    'Fort Myers': cities_fc.filter(ee.Filter.eq('NAME', 'Fort Myers')).geometry()\n",
        "}\n",
        "\n",
        "hurricane_dates = pd.DataFrame({\n",
        "    'name': ['Hermine', 'Matthew', 'Irma', 'Michael', 'Sally','Ian', 'Idalia', 'Debby', 'Helene', 'Milton'],\n",
        "    'date': ['2016-09-02', '2016-10-7', '2017-09-10', '2018-10-10', '2020-09-16', '2022-09-28', '2023-08-30', '2024-08-05', '2024-09-27', '2024-10-10']\n",
        "})\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyNni8FsP0Ss"
      },
      "source": [
        "def get_baseline(city_geom, hurricane_date):\n",
        "    start = ee.Date(hurricane_date).advance(-30, 'day')\n",
        "    end = ee.Date(hurricane_date)\n",
        "\n",
        "    baseline_img = viirs.filterDate(start, end).mean().select(\"Gap_Filled_DNB_BRDF_Corrected_NTL\")\n",
        "\n",
        "    baseline_val = baseline_img.reduceRegion(\n",
        "        reducer=ee.Reducer.mean(),\n",
        "        geometry=city_geom,\n",
        "        scale=500\n",
        "    ).get(\"Gap_Filled_DNB_BRDF_Corrected_NTL\")\n",
        "\n",
        "    return baseline_val\n",
        "\n",
        "def daily_pct_recovery(city_geom, hurricane_date, baseline_val):\n",
        "    start = ee.Date(hurricane_date)\n",
        "    end = start.advance(30, 'day')\n",
        "    images = viirs.filterDate(start, end).select(\"Gap_Filled_DNB_BRDF_Corrected_NTL\")\n",
        "\n",
        "    def calc_pct(image):\n",
        "        mean_val = image.reduceRegion(\n",
        "            reducer=ee.Reducer.mean(),\n",
        "            geometry=city_geom,\n",
        "            scale=500\n",
        "        ).get(\"Gap_Filled_DNB_BRDF_Corrected_NTL\")\n",
        "\n",
        "        # Use ee.Algorithms.If to check for nulls directly\n",
        "        pct_recovered = ee.Algorithms.If(\n",
        "            ee.Algorithms.IsEqual(baseline_val, None),\n",
        "            None,  # skip if baseline is null\n",
        "            ee.Algorithms.If(\n",
        "                ee.Algorithms.IsEqual(mean_val, None),\n",
        "                None,  # skip if mean_val is null\n",
        "                ee.Number(mean_val).divide(baseline_val).multiply(100)  # otherwise calculate %\n",
        "            )\n",
        "        )\n",
        "\n",
        "        return image.set('pct_recovered', pct_recovered)\n",
        "\n",
        "    return images.map(calc_pct)\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwNoBjtyP3P8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "a69689d2-45fe-4622-d731-617d0aad1068"
      },
      "source": [
        "from google.colab import files\n",
        "all_data = []\n",
        "\n",
        "for city_name, city_geom in cities.items():\n",
        "    for idx, row in hurricane_dates.iterrows():\n",
        "        baseline_val = get_baseline(city_geom, row['date'])\n",
        "        daily_images = daily_pct_recovery(city_geom, row['date'], baseline_val)\n",
        "\n",
        "        # Convert to list for export\n",
        "        pct_list = daily_images.aggregate_array('pct_recovered').getInfo()\n",
        "        for day, pct in enumerate(pct_list):\n",
        "            all_data.append({\n",
        "                'city': city_name,\n",
        "                'hurricane': row['name'],\n",
        "                'date': row['date'],\n",
        "                'day_after': day,\n",
        "                'percent_recovered': pct\n",
        "            })\n",
        "\n",
        "df = pd.DataFrame(all_data)\n",
        "df.to_csv('hurricane_recovery.csv', index=False)\n",
        "files.download(\"hurricane_recovery.csv\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ace11cd9-ab51-4c37-a90a-4f6848231470\", \"hurricane_recovery.csv\", 69171)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpFkh36BVLMh"
      },
      "source": [
        "## Documentation\n",
        "\n",
        "- The full documentation of the Google Earth Engine Python API is available [here](https://developers.google.com/earth-engine/api_docs).\n",
        "- The Google Earth Engine User Guide is available [here](https://developers.google.com/earth-engine).\n",
        "- Some tutorials are available [here](https://developers.google.com/earth-engine/tutorials).\n",
        "- An example based on the Google Earth Engine Javascript console dedicated to Land Surface Temperature estimation is provided in the open access supplementary material of [Benz et al., (2017)](https://iopscience.iop.org/article/10.1088/1748-9326/aa5fb0/meta). You can access the code [here](https://code.earthengine.google.com/4a1bc64dbc3351a1e364490758d4cf2d).\n",
        "\n",
        "## Acknowledgements\n",
        "\n",
        "Thanks to Susanne Benz and Justin Braaten for reviewing and helping write this tutorial."
      ]
    }
  ]
}